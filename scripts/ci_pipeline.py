#!/usr/bin/env python3
"""
Script d'intÃ©gration continue pour CourseScope
ExÃ©cute tous les tests et valide la compatibilitÃ© entre les composants
"""

import sys
import subprocess
import os
import time
import json
from pathlib import Path
from datetime import datetime


def run_command(cmd, description, timeout=300):
    """ExÃ©cute une commande et retourne le rÃ©sultat"""
    print(f"\n{'='*60}")
    print(f"ğŸ”§ {description}")
    print(f"{'='*60}")
    
    start_time = time.time()
    
    try:
        result = subprocess.run(
            cmd, 
            shell=True, 
            capture_output=True, 
            text=True, 
            timeout=timeout,
            cwd=Path(__file__).parent.parent
        )
        
        duration = time.time() - start_time
        
        if result.returncode == 0:
            print(f"âœ… {description} : SUCCESS ({duration:.2f}s)")
            return True, result.stdout, duration
        else:
            print(f"âŒ {description} : FAILED ({duration:.2f}s)")
            print(f"STDERR: {result.stderr}")
            return False, result.stderr, duration
            
    except subprocess.TimeoutExpired:
        print(f"â° {description} : TIMEOUT ({timeout}s)")
        return False, f"Command timeout after {timeout}s", timeout
    except Exception as e:
        print(f"ğŸ’¥ {description} : ERROR - {str(e)}")
        return False, str(e), 0


def run_unit_tests():
    """ExÃ©cute les tests unitaires"""
    success, output, duration = run_command(
        "python -m pytest tests/unit_tests.py -v",
        "Tests unitaires"
    )
    return success, duration


def run_api_tests():
    """ExÃ©cute les tests API"""
    # DÃ©marrer le serveur API pour les tests
    print("\nğŸš€ DÃ©marrage du serveur API pour les tests...")
    
    api_process = None
    try:
        # Lancer le serveur en arriÃ¨re-plan
        api_process = subprocess.Popen(
            [sys.executable, "-m", "uvicorn", "backend.api.main:app", "--host", "0.0.0.0", "--port", "8000"],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE
        )
        
        # Attendre que le serveur soit prÃªt
        time.sleep(5)
        
        success, output, duration = run_command(
            "python -m pytest tests/api_tests.py -v",
            "Tests API"
        )
        
        return success, duration
        
    finally:
        if api_process:
            api_process.terminate()
            api_process.wait()


def run_compatibility_tests():
    """ExÃ©cute les tests de compatibilitÃ©"""
    success, output, duration = run_command(
        "python -m pytest tests/compat_tests.py -v",
        "Tests de compatibilitÃ© Streamlit/API"
    )
    return success, duration


def run_sync_tests():
    """ExÃ©cute les tests de synchronisation"""
    # DÃ©marrer les deux serveurs pour les tests de sync
    api_process = None
    streamlit_process = None
    
    try:
        print("\nğŸš€ DÃ©marrage des serveurs pour les tests de synchronisation...")
        
        # DÃ©marrer API
        api_process = subprocess.Popen(
            [sys.executable, "-m", "uvicorn", "backend.api.main:app", "--host", "0.0.0.0", "--port", "8000"],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE
        )
        
        # DÃ©marrer Streamlit
        streamlit_process = subprocess.Popen(
            [sys.executable, "-m", "streamlit", "run", "CourseScope.py", "--server.port", "8501", "--server.headless", "true"],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE
        )
        
        # Attendre que les serveurs soient prÃªts
        time.sleep(10)
        
        success, output, duration = run_command(
            "python -m pytest tests/sync_tests.py -v",
            "Tests de synchronisation"
        )
        
        return success, duration
        
    finally:
        if api_process:
            api_process.terminate()
            api_process.wait()
        if streamlit_process:
            streamlit_process.terminate()
            streamlit_process.wait()


def run_load_tests():
    """ExÃ©cute les tests de charge"""
    print("\nğŸ”¥ DÃ©marrage des tests de charge...")
    
    try:
        # Simuler un test de charge
        success, output, duration = run_command(
            "python tests/api_tests.py",
            "Tests de charge API"
        )
        
        return success, duration
    except Exception as e:
        print(f"âš ï¸ Tests de charge non disponibles: {e}")
        return True, 0  # Non bloquant


def run_code_quality_checks():
    """ExÃ©cute les vÃ©rifications de qualitÃ© du code"""
    checks = [
        ("black --check .", "Formatage Black"),
        ("isort --check-only .", "Import sorting"),
        ("flake8 . --max-line-length=100", "Linting Flake8"),
        ("mypy . --ignore-missing-imports", "Type checking MyPy")
    ]
    
    all_success = True
    total_duration = 0
    
    for cmd, description in checks:
        success, _, duration = run_command(cmd, description)
        all_success = all_success and success
        total_duration += duration
    
    return all_success, total_duration


def check_dependencies():
    """VÃ©rifie que toutes les dÃ©pendances sont installÃ©es"""
    success, _, duration = run_command(
        "pip list | findstr -i \"streamlit fastapi uvicorn pandas numpy\"",
        "VÃ©rification des dÃ©pendances"
    )
    return success, duration


def generate_report(results):
    """GÃ©nÃ¨re un rapport d'exÃ©cution"""
    report = {
        "timestamp": datetime.now().isoformat(),
        "total_duration": sum(r["duration"] for r in results),
        "results": results,
        "summary": {
            "total_tests": len(results),
            "passed": sum(1 for r in results if r['success']),
            "failed": sum(1 for r in results if not r["success"]),
            "success_rate": f"{(sum(1 for r in results if r['success']) / len(results) * 100):.1f}%"
        }
    }
    
    # Sauvegarder le rapport
    report_path = Path("ci_report.json")
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    return report


def main():
    """Fonction principale d'intÃ©gration continue"""
    print(f"\nğŸ¯ DÃ‰MARRAGE DE L'INTÃ‰GRATION CONTINUE - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    results = []
    
    # 1. VÃ©rification des dÃ©pendances
    success, duration = check_dependencies()
    results.append({
        "name": "VÃ©rification des dÃ©pendances",
        "success": success,
        "duration": duration
    })
    
    if not success:
        print("âŒ DÃ©pendances manquantes. ArrÃªt.")
        return False
    
    # 2. Tests unitaires
    success, duration = run_unit_tests()
    results.append({
        "name": "Tests unitaires",
        "success": success,
        "duration": duration
    })
    
    # 3. VÃ©rification de qualitÃ© du code
    success, duration = run_code_quality_checks()
    results.append({
        "name": "QualitÃ© du code",
        "success": success,
        "duration": duration
    })
    
    # 4. Tests API
    success, duration = run_api_tests()
    results.append({
        "name": "Tests API",
        "success": success,
        "duration": duration
    })
    
    # 5. Tests de compatibilitÃ©
    success, duration = run_compatibility_tests()
    results.append({
        "name": "Tests de compatibilitÃ©",
        "success": success,
        "duration": duration
    })
    
    # 6. Tests de synchronisation (optionnel)
    try:
        success, duration = run_sync_tests()
        results.append({
            "name": "Tests de synchronisation",
            "success": success,
            "duration": duration
        })
    except Exception as e:
        print(f"âš ï¸ Tests de synchronisation ignorÃ©s: {e}")
        results.append({
            "name": "Tests de synchronisation",
            "success": True,
            "duration": 0,
            "skipped": True
        })
    
    # 7. Tests de charge (optionnel)
    success, duration = run_load_tests()
    results.append({
        "name": "Tests de charge",
        "success": success,
        "duration": duration
    })
    
    # GÃ©nÃ©rer le rapport
    report = generate_report(results)
    
    # Afficher le rÃ©sumÃ©
    print(f"\n{'='*80}")
    print("ğŸ“Š RAPPORT D'INTÃ‰GRATION CONTINUE")
    print(f"{'='*80}")
    
    total_duration = report["total_duration"]
    passed = report["summary"]["passed"]
    failed = report["summary"]["failed"]
    success_rate = report["summary"]["success_rate"]
    
    print(f"â±ï¸ DurÃ©e totale: {total_duration:.2f}s")
    print(f"âœ… Tests rÃ©ussis: {passed}")
    print(f"âŒ Tests Ã©chouÃ©s: {failed}")
    print(f"ğŸ“ˆ Taux de rÃ©ussite: {success_rate}")
    
    if failed > 0:
        print(f"\nğŸ” Tests Ã©chouÃ©s:")
        for result in results:
            if not result["success"]:
                print(f"   âŒ {result['name']}")
    
    print(f"\nğŸ“„ Rapport dÃ©taillÃ©: ci_report.json")
    
    # Nettoyer
    try:
        import shutil
        if Path("./test_activities").exists():
            shutil.rmtree("./test_activities")
        if Path("./test_sync").exists():
            shutil.rmtree("./test_sync")
    except:
        pass
    
    # Retourner le rÃ©sultat global
    overall_success = failed == 0
    
    if overall_success:
        print(f"\nğŸ‰ INTÃ‰GRATION CONTINUE : SUCCESS âœ…")
        return True
    else:
        print(f"\nğŸ’¥ INTÃ‰GRATION CONTINUE : FAILED âŒ")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)